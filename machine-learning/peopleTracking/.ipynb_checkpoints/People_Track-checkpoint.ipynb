{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!python3 -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install --upgrade opencv-python\n",
    "!{sys.executable} -m pip install pyqtwebengine==5.12.0\n",
    "!{sys.executable} -m pip install pyqt5==5.12.0\n",
    "!{sys.executable} -m pip install typed-ast==1.3.0\n",
    "!{sys.executable} -m pip install --upgrade imageai --ignore-installed certifi\n",
    "!{sys.executable} -m pip install keras==2.3.1\n",
    "!{sys.executable} -m pip install tensorflow==2.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Bibliotecas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from imageai.Detection import ObjectDetection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Função para extração de frames de videos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, fr=2):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    id_frame = 0\n",
    "    while id_frame<=total_frames:\n",
    "        cap.set(1, id_frame)\n",
    "        success, frame = cap.read()\n",
    "        if type(frame) != type(None):\n",
    "            frames.append(frame)\n",
    "        id_frame+=fr\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Extrair frames:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames = extract_frames('/Users/m04m/Downloads/Frutas.avi')\n",
    "len(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Apresentar um frame para validação:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(cv2.cvtColor(frames[0], cv2.COLOR_BGRA2RGB))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Iniciar o modelo yolo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsTinyYOLOv3()\n",
    "detector.setModelPath(\"yolo-tiny.h5\")\n",
    "detector.loadModel()\n",
    "custom_objects = detector.CustomObjects(person=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Reconhecimento de pessoa por frame:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_h = 8\n",
    "final_img = []\n",
    "for img in tqdm(frames):\n",
    "\n",
    "    detected_image_array, detections = detector.detectCustomObjectsFromImage(\n",
    "        input_image=img, input_type=\"array\", output_type=\"array\",\n",
    "        custom_objects=custom_objects, minimum_percentage_probability=75)\n",
    "    \n",
    "    new_img = np.zeros(img.shape)\n",
    "    for person in detections:\n",
    "        y_min = person['box_points'][1]\n",
    "        x_min = person['box_points'][0]\n",
    "        y_max =  person['box_points'][3]\n",
    "        x_max =  person['box_points'][2]\n",
    "        cv2.rectangle(new_img, (x_min,y_max-rect_h), (x_max,y_max), (0,255,0), -1)\n",
    "        #cv2.line(new_img, (x_min,y_max-rect_h), (x_max,y_max), (0,255,0), 4)\n",
    "        \n",
    "    final_img.append(new_img[:,:,1]/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) Calculo de frequencias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi_img = np.sum(final_img, axis=0)\n",
    "combi_img[combi_img.shape[0] - int(rect_h+rect_h/3):,:] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8) Mapa de frequencias (tracking)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_img = (combi_img != 0) +0 \n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(track_img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9) Mapa heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_background = cv2.cvtColor(frames[0], cv2.COLOR_BGRA2RGB)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(img_background)\n",
    "plt.imshow(combi_img, cmap='jet', alpha=0.5)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
